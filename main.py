from fastapi import FastAPI, Request, Form
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import json
import random
import os
import time
import asyncio
from openai import AsyncOpenAI
from dotenv import load_dotenv
import markdown
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import re

# Load environment variables
load_dotenv()

app = FastAPI()

# --- Google Sheets Setup ---
SCOPES = ["https://spreadsheets.google.com/feeds", 'https://www.googleapis.com/auth/spreadsheets',
          "https://www.googleapis.com/auth/drive.file", "https://www.googleapis.com/auth/drive"]

def get_google_sheet_client():
    # Check for credentials in environment variable first (Best for Render/Cloud)
    creds_json = os.getenv("GOOGLE_CREDENTIALS_JSON")
    
    if creds_json:
        try:
            creds_dict = json.loads(creds_json)
            creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
            client = gspread.authorize(creds)
            return client
        except Exception as e:
            print(f"‚ö†Ô∏è Error authenticating with GOOGLE_CREDENTIALS_JSON: {e}")
            return None
            
    # Fallback to file (Best for Local Development)
    creds_file = 'env.json' 
    if os.path.exists(creds_file):
        try:
            creds = Credentials.from_service_account_file(creds_file, scopes=SCOPES)
            client = gspread.authorize(creds)
            return client
        except Exception as e:
            print(f"‚ö†Ô∏è Error authenticating with file '{creds_file}': {e}")
            return None
            
    print(f"‚ö†Ô∏è Warning: neither 'GOOGLE_CREDENTIALS_JSON' env var nor '{creds_file}' found. Google Sheets integration will not work.")
    return None



# --- Constants ---

TEAM_3_SCHOOLS = [
    "TH, THCS v√† THPT iSchool Quy Nh∆°n",
    "THPT L√Ω T·ª± Tr·ªçng",
    "THPT Nguy·ªÖn Du",
    "THPT Nguy·ªÖn H·ªìng ƒê·∫°o",
    "THPT Nguy·ªÖn H·ªØu Quang",
    "THPT Nguy·ªÖn Th√°i H·ªçc",
    "THPT Phan B·ªôi Ch√¢u",
    "THPT S·ªë 1 Ph√π M·ªπ",
    "THPT S·ªë 2 An Nh∆°n",
    "THPT S·ªë 2 Ph√π M·ªπ",
    "THPT S·ªë 3 An Nh∆°n",
    "THPT S·ªë 3 Tuy Ph∆∞·ªõc",
    "THPT Tr∆∞ng V∆∞∆°ng",
    "THPT Xu√¢n Di·ªáu",
    "TT GDNN-GDTX An Nh∆°n",
    "TT GDTX tinh B√¨nh ƒê·ªãnh",
    "Tr∆∞·ªùng THPT L∆∞∆°ng Th·∫ø Vinh",
    "TH, THCS&THPT Qu·ªëc t·∫ø Vi·ªát Nam Singapore",
    "THCS&THPT iSchool Nha Trang",
    "THPT chuy√™n L√™ Qu√Ω ƒê√¥n",
    "THPT ƒêo√†n Th·ªã ƒêi·ªÉm",
    "THPT H√† Huy T·∫≠p",
    "THPT Hermann Gmeiner",
    "THPT Ho√†ng Hoa Th√°m",
    "THPT Ho√†ng VƒÉn Th·ª•",
    "THPT Hu·ª≥nh Th√∫c Kh√°ng",
    "THPT L√™ H·ªìng Phong",
    "THPT L√™ Th√°nh T√¥n",
    "THPT Ng√¥ Gia T·ª±",
    "THPT Nguy·ªÖn Ch√≠ Thanh",
    "THPT Nguy·ªÖn Hu·ªá",
    "THCS&THPT Nguy·ªÖn Th√°i B√¨nh",
    "THPT Nguy·ªÖn Thi·ªán Thu·∫≠t",
    "THPT Nguy·ªÖn Tr√£i",
    "THPT Nguy·ªÖn VƒÉn Tr·ªói",
    "THPT Ph·∫°m VƒÉn ƒê·ªìng",
    "THPT T√¥ VƒÉn ∆†n",
    "THPT Tr·∫ßn B√¨nh Tr·ªçng",
    "THPT Tr·∫ßn Cao V√¢n",
    "THPT Tr·∫ßn H∆∞ng ƒê·∫°o",
    "THPT Tr·∫ßn Qu√Ω C√°p",
    "Tr∆∞·ªùng THPT V√µ Nguy√™n Gi√°p",
    "Tr∆∞·ªùng THPT Ba T∆°",
    "Tr∆∞·ªùng THPT B√¨nh S∆°n",
    "Tr∆∞·ªùng THPT Ph·∫°m Ki·ªát"
]

TEAM_1_SCHOOLS = [
    "THPT H√πng V∆∞∆°ng",
    "THPT Ng√¥ M√¢y",
    "THPT s·ªë 1 Quang Trung",
    "THPT S·ªë 1 An Nh∆°n",
    "THPT S·ªë 2 Tuy ph∆∞·ªõc",
    "THPT S·ªë 3 Ph√π C√°t",
    "THPT TƒÉng B·∫°t H·ªï",
    "THPT Tr·∫ßn Cao V√¢n",
    "THPT Tr·∫ßn Quang Di·ªáu",
    "THPT V√¢n Canh",
    "THPT Vƒ©nh Th·∫°nh",
    "THPT V√µ Gi·ªØ",
    "THPT M·∫°c ƒêƒ©nh Chi",
    "Tr∆∞·ªùng Qu·ªëc t·∫ø Ch√¢u √Å Th√°i B√¨nh D∆∞∆°ng",
    "Tr∆∞·ªùng THCS v√† THPT Ph·∫°m H·ªìng Th√°i",
    "Tr∆∞·ªùng THCS v√† THPT Y ƒê√¥n",
    "THPT Chu VƒÉn An",
    "Tr∆∞·ªùng THCS&THPT KpƒÉ Kl∆°ng",
    "Tr∆∞·ªùng THCS, THPT Nguy·ªÖn VƒÉn C·ª´",
    "Tr∆∞·ªùng THPT A Sanh",
    "THPT L√Ω Th∆∞·ªùng Ki·ªát",
    "Tr∆∞·ªùng THPT H√† Huy T·∫≠p",
    "Tr∆∞·ªùng THPT Hu·ª≥nh Th√∫c Kh√°ng",
    "Tr∆∞·ªùng THPT L√™ Ho√†n",
    "Tr∆∞·ªùng THPT L√™ H·ªìng Phong",
    "Tr∆∞·ªùng THPT L√™ L·ª£i",
    "Tr∆∞·ªùng THPT L√™ Qu√Ω ƒê√¥n",
    "Nguy·ªÖn Khuy·∫øn",
    "Tr∆∞·ªùng THPT L√™ Th√°nh T√¥ng",
    "Tr∆∞·ªùng THPT Nguy·ªÖn B·ªânh Khi√™m",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Ch√≠ Thanh",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Du",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Hu·ªá",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Th√°i H·ªçc",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Tr√£i",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Tr∆∞·ªùng T·ªô",
    "Tr∆∞·ªùng THPT Ph·∫°m VƒÉn ƒê·ªìng",
    "Tr∆∞·ªùng THPT Phan B·ªôi Ch√¢u",
    "Tr∆∞·ªùng THPT Pleiku",
    "Tr∆∞·ªùng THPT Quang Trung",
    "Tr∆∞·ªùng THPT Tr·∫ßn H∆∞ng ƒê·∫°o",
    "Tr∆∞·ªùng THPT Tr·∫ßn Ph√∫",
    "Tr∆∞·ªùng THPT Tr∆∞·ªùng Chinh",
    "Tr∆∞·ªùng THPT V√µ VƒÉn Ki·ªát",
    "Tr∆∞·ªùng PT D√¢n t·ªôc N·ªôi tr√∫ tinh"
]

TEAM_2_SCHOOLS = [
    "PTDTNT THPT B√¨nh ƒê·ªãnh",
    "THPT An L√£o",
    "THPT B√πi Th·ªã Xu√¢n",
    "THPT chuy√™n Chu VƒÉn An",
    "THPT chuy√™n L√™ Qu√Ω ƒê√¥n",
    "THPT FPT - Th√†nh ph·ªë Quy Nh∆°n",
    "THPT Ho√†i √Çn",
    "THPT M·ªπ Th·ªç",
    "THPT Nguy·ªÖn B·ªânh Khi√™m",
    "THPT Nguy·ªÖn Di√™u",
    "THPT Nguy·ªÖn Tr√¢n",
    "THPT S·ªë 1 Ph√π C√°t",
    "THPT S·ªë 2 Ph√π C√°t",
    "THPT V√µ Lai",
    "THPT Binh D∆∞∆°ng",
    "Tr∆∞·ªùng THPT Chi LƒÉng",
    "Tr∆∞·ªùng THPT Chuy√™n H√πng V∆∞∆°ng",
    "Tr∆∞·ªùng THPT Ho√†ng Hoa Th√°m",
    "Tr∆∞·ªùng THPT Nguy·ªÖn T·∫•t Th√†nh",
    "Tr∆∞·ªùng THPT Tr·∫ßn Qu·ªëc Tu·∫•n",
    "Tr·∫ßn Cao V√¢n",
    "TT GDTX tinh",
    "Tr∆∞·ªùng THPT Ya Ly",
    "THPT Pleime",
    "Ph·ªï th√¥ng Duy T√¢n",
    "THCS v√† THPT Nguy·ªÖn Khuy·∫øn",
    "Nguy·ªÖn B√° Ng·ªçc",
    "THCS v√† THPT Nguy·ªÖn Vi·∫øt Xu√¢n",
    "THCS v√† THPT V√µ Nguy√™n Gi√°p",
    "THPT Chuy√™n L∆∞∆°ng VƒÉn Ch√°nh",
    "THPT L√™ H·ªìng Phong",
    "THPT L√™ L·ª£i",
    "THPT L√™ Th√†nh Ph∆∞∆°ng",
    "THPT L√™ Trung Ki√™n",
    "THPT Nguy·ªÖn Tr√£i",
    "THPT Ng√¥ Gia T·ª±",
    "THPT Nguy·ªÖn Du",
    "Nguy·ªÖn Th·ªã Minh Khai",
    "THPT Nguy·ªÖn C√¥ng Tr·ª©",
    "THPT Nguy·ªÖn Hu·ªá",
    "THPT Nguy·ªÖn VƒÉn Linh",
    "THPT Phan B·ªôi Ch√¢u",
    "THPT Phan Chu Trinh",
    "THPT Phan ƒê√¨nh Ph√πng",
    "THPT Tr·∫ßn B√¨nh Tr·ªçng",
    "V√µ Th·ªã S√°u",
    "Tr·∫ßn Qu·ªëc Tu·∫•n",
    "THPT Tr·∫ßn Ph√∫",
    "THPT Tr·∫ßn Suy·ªÅn",
    "THPT T√¥n ƒê·ª©c Th·∫Øng",
    "THPT Ph·∫°m VƒÉn ƒê·ªìng",
    "THPT Nguy·ªÖn Th√°i B√¨nh",
    "THCS v√† THPT Chu VƒÉn An",
    "THPT Nguy·ªÖn Tr∆∞·ªùng T·ªô",
    "THCS v√† THPT V·∫°n T∆∞·ªùng",
    "ƒêinh Ti√™n Ho√†ng",
    "Tr∆∞·ªùng THPT L√™ Trung ƒê√¨nh",
    "Tr∆∞·ªùng THPT S·ªë 1 T∆∞ Nghƒ©a",
    "Trung t√¢m GDNN-GDTX huy·ªán M·ªô ƒê·ª©c",
    "Trung t√¢m GDTX tinh Qu·∫£ng Ng√£i"
]

TEAM_4_SCHOOLS = [
    "PTDTNT THCS & THPT V√¢n Canh",
    "Qu·ªëc H·ªçc Quy Nh∆°n",
    "THPT An L∆∞∆°ng",
    "THPT H√≤a B√¨nh",
    "THPT Ng√¥ L√™ T√¢n",
    "THPT Nguy·ªÖn ƒê√¨nh Chi·ªÉu",
    "THPT s·ªë 1 Nguy·ªÖn Hu·ªá",
    "THPT s·ªë 1 Nguy·ªÖn Tr∆∞·ªùng T·ªô",
    "THPT Quy Nh∆°n",
    "THPT S·ªë 1 Tuy ph∆∞·ªõc",
    "THPT Tam Quan",
    "THPT T√¢y S∆°n",
    "LI√äN C·∫§P TH√ÄNH PH·ªê GI√ÅO D·ª§C",
    "THPT Ba Gia",
    "THPT Chu VƒÉn An",
    "THPT chuy√™n L√™ Khi·∫øt",
    "THPT L√™ Qu√Ω ƒê√¥n",
    "THPT L∆∞∆°ng Th·∫ø Vinh",
    "THPT L√Ω S∆°n",
    "THPT Quang Trung",
    "THPT Ph·∫°m VƒÉn ƒê·ªìng",
    "THPT S·ªë 1 ƒê·ª©c Ph·ªï",
    "THPT S·ªë 1 Nghƒ©a H√†nh",
    "THPT S·ªë 2 ƒê·ª©c Ph·ªï",
    "THPT S·ªë 2 M·ªô ƒê·ª©c",
    "THPT S·ªë 2 Nghƒ©a H√†nh",
    "THPT S∆°n M·ªπ",
    "S∆°n h√†",
    "Thu X√†",
    "Tr·∫ßn K·ª≥ Phong",
    "THPT Tr·∫ßn Qu·ªëc Tu·∫•n"
]


BLANKS_SCHOOLS = [
    "THPT Nguy·ªÖn Trung Tr·ª±c",
    "Trung t√¢m GDNN-GDTX Quy Nh∆°n",
    "TT GDNN-GDTX Ph√π C√°t",
    "Tr∆∞·ªùng THCS v√† THPT Ph·∫°m Ki·ªát",
    "Tr∆∞·ªùng THPT D√¢n t·ªôc n·ªôi tr√∫ t·ªânh Qu·∫£ng Ng√£i",
    "Tr∆∞·ªùng THPT Hu·ª≥nh Th√∫c Kh√°ng",
    "Tr∆∞·ªùng THPT Nguy·ªÖn C√¥ng Ph∆∞∆°ng",
    "Tr∆∞·ªùng THPT S·ªë 2 T∆∞ Nghƒ©a",
    "Tr∆∞·ªùng THPT T√¢y Tr√†",
    "Tr∆∞·ªùng THPT Tr√† B·ªìng",
    "Tr∆∞·ªùng THPT Tr·∫ßn Quang Di·ªáu",
    "Tr∆∞·ªùng THPT T∆∞ th·ª•c Ho√†ng VƒÉn Th·ª•",
    "Tr∆∞·ªùng THPT Nguy·ªÖn Tr√£i",
    "Tr∆∞·ªùng THPT chuy√™n L√™ Qu√≠ ƒê√¥n",
    "Tr∆∞·ªùng THPT An Ph∆∞·ªõc",
    "Tr∆∞·ªùng THPT Chu VƒÉn An",
    "Tr∆∞·ªùng THPT iSchool",
    "Tr∆∞·ªùng THPT Phan Chu Trinh",
    "Tr∆∞·ªùng THPT Ninh H·∫£i",
    "Tr∆∞·ªùng THPT T√¥n ƒê·ª©c Th·∫Øng",
    "TTGDTX Ninh Thu·∫≠n",
    "THCS - THPT ƒê·∫∑ng Ch√≠ Thanh",
    "THPT Nguy·ªÖn Du",
    "TH - THCS - THPT Hoa Sen",
    "THPT Tr∆∞·ªùng Chinh",
    "THPT Th√°p Ch√†m"
]

def check_school_team(school_name):
    """
    Check which team the school belongs to.
    Returns: "team 1", "team 2", "team 3", "team 4", "blanks" or None
    """
    if not school_name:
        return None
    
    school_name_lower = school_name.lower().strip()
    
    # Common prefixes to ignore for better matching
    prefixes = ["tr∆∞·ªùng ", "thpt ", "tr∆∞·ªùng thpt ", "tt ", "trung t√¢m ", "thcs v√† thpt ", "thcs & thpt ", "ptdtnt ", "th, ", "th - "]
    
    # Normalize input school name
    normalized_input = school_name_lower
    for prefix in prefixes:
        if normalized_input.startswith(prefix):
            normalized_input = normalized_input[len(prefix):].strip()
    
    # Helper to check against a list
    def check_list(school_list):
        for school in school_list:
            # Normalize list item
            item_normalized = school.lower()
            for prefix in prefixes:
                if item_normalized.startswith(prefix):
                    item_normalized = item_normalized[len(prefix):].strip()
            
            # Check containment
            if normalized_input in item_normalized or item_normalized in normalized_input:
                return True
        return False

    if check_list(BLANKS_SCHOOLS):
        return "blanks"

    if check_list(TEAM_1_SCHOOLS):
        return "team 1"
    
    if check_list(TEAM_2_SCHOOLS):
        return "team 2"
        
    if check_list(TEAM_3_SCHOOLS):
        return "team 3"
        
    if check_list(TEAM_4_SCHOOLS):
        return "team 4"
        
    return None

async def init_sheet_headers():
    """Ensure Google Sheet has correct headers and formatting"""
    client = await asyncio.to_thread(get_google_sheet_client)
    if not client:
        return

    try:
        spreadsheet_url = "https://docs.google.com/spreadsheets/d/1RTxOi5IYcYDL5VaCAiwK9B0T15K5ntSnWLJ4EwD_Rlg/edit?usp=sharing"
        sheet = await asyncio.to_thread(client.open_by_url, spreadsheet_url)
        
        target_headers = ["H·ªç v√† t√™n", "S·ªë ƒëi·ªán tho·∫°i", "Email", "T·ªânh th√†nh", "Tr∆∞·ªùng THPT", "K·∫øt qu·∫£ AI ƒë·ªÅ xu·∫•t", "Ng√†nh ph·ª• 1", "Ng√†nh ph·ª• 2"]
        
        # --- 1. Init Main Sheet (Sheet1) ---
        worksheet = await asyncio.to_thread(sheet.get_worksheet, 0)
        current_headers = await asyncio.to_thread(worksheet.row_values, 1)
        
        if not current_headers:
            print("‚è≥ Main Sheet is empty. Adding headers...")
            await asyncio.to_thread(worksheet.append_row, target_headers)
        elif current_headers != target_headers:
             # Just update headers to be sure
            cell_list = await asyncio.to_thread(worksheet.range, 'A1:H1')
            for i, cell in enumerate(cell_list):
                if i < len(target_headers):
                    cell.value = target_headers[i]
            await asyncio.to_thread(worksheet.update_cells, cell_list)
        
        await asyncio.to_thread(worksheet.freeze, rows=1)
        print("‚úÖ Main Sheet (Sheet1) initialized.")

        # --- 2. Init Sub-Sheets (team 1, team 2, team 3, team 4, blanks) ---
        for sheet_title in ["team 1", "team 2", "team 3", "team 4", "blanks"]:
            try:
                # Try to get the sheet
                ws_sub = await asyncio.to_thread(sheet.worksheet, sheet_title)
            except gspread.WorksheetNotFound:
                # Create if not exists
                print(f"‚è≥ Creating sheet '{sheet_title}'...")
                ws_sub = await asyncio.to_thread(sheet.add_worksheet, title=sheet_title, rows=1000, cols=10)
            
            # Check/init headers
            current_headers_sub = await asyncio.to_thread(ws_sub.row_values, 1)
            if not current_headers_sub:
                await asyncio.to_thread(ws_sub.append_row, target_headers)
            elif current_headers_sub != target_headers:
                cell_list = await asyncio.to_thread(ws_sub.range, 'A1:H1')
                for i, cell in enumerate(cell_list):
                    if i < len(target_headers):
                        cell.value = target_headers[i]
                await asyncio.to_thread(ws_sub.update_cells, cell_list)
            
            await asyncio.to_thread(ws_sub.freeze, rows=1)
            print(f"‚úÖ Sheet '{sheet_title}' initialized.")

    except Exception as e:
        print(f"‚ö†Ô∏è Error initializing Google Sheet: {e}")

# Initialize sheet headers on startup
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(init_sheet_headers())

async def save_student_info(student_data):
    """Save student info to Google Sheet"""
    client = await asyncio.to_thread(get_google_sheet_client)
    if not client:
        return

    try:
        # Spreadsheet URL from user
        spreadsheet_url = "https://docs.google.com/spreadsheets/d/1RTxOi5IYcYDL5VaCAiwK9B0T15K5ntSnWLJ4EwD_Rlg/edit?usp=sharing"
        
        # Open the spreadsheet by URL
        try:
            sheet = await asyncio.to_thread(client.open_by_url, spreadsheet_url)
        except gspread.SpreadsheetNotFound:
            print(f"‚ö†Ô∏è Spreadsheet not found. Please check permissions for the URL.")
            return

        # Prepare row data
        row = [
            student_data.get('student_name', ''),
            student_data.get('student_phone', ''),
            student_data.get('student_email', ''),
            student_data.get('student_province', ''),
            student_data.get('student_school', ''),
            student_data.get('predicted_major', ''),
            student_data.get('sub_major_1', ''),
            student_data.get('sub_major_2', '')
        ]

        # 1. Save to Main Worksheet (index 0)
        worksheet = await asyncio.to_thread(sheet.get_worksheet, 0)
        await asyncio.to_thread(worksheet.append_row, row)
        print(f"‚úÖ Saved data for {student_data.get('student_name')} to Main Sheet")
        
        # 2. Check which team the school belongs to (Team 1, 2, 3, 4 or blanks)
        student_school = student_data.get('student_school', '')
        team_name = check_school_team(student_school) # Returns "team 1", "team 2", "team 3", "team 4", "blanks" or None
        
        if team_name:
            try:
                ws_team = await asyncio.to_thread(sheet.worksheet, team_name)
                await asyncio.to_thread(ws_team.append_row, row)
                print(f"‚úÖ Saved data for {student_data.get('student_name')} to '{team_name}' Sheet")
            except gspread.WorksheetNotFound:
                print(f"‚ö†Ô∏è Sheet '{team_name}' not found (should have been created setup).")

    except Exception as e:
        print(f"‚ö†Ô∏è Error saving to Google Sheet: {e}")


# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Setup templates
templates = Jinja2Templates(directory="templates")

# --- Helper Functions ---

def load_questions():
    """Read questions.json"""
    try:
        with open('questions.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('questions', [])
    except FileNotFoundError:
        print("‚ö†Ô∏è Warning: 'questions.json' not found.")
        return []
    except json.JSONDecodeError as e:
        print(f"‚ö†Ô∏è Error decoding 'questions.json': {e}")
        return []

def load_system_prompt():
    """Read System_prompt.txt"""
    try:
        with open('System_prompt.txt', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n h∆∞·ªõng nghi·ªáp."

async def generate_ai_advice(user_answers_text):
    """
    Call AI to generate advice using OpenRouter.
    """
    system_prompt = await asyncio.to_thread(load_system_prompt)
    
    # Get API Key
    api_key = os.getenv("OPENROUTER_API_KEY")
    
    if not api_key:
        return "‚ö†Ô∏è **L·ªói:** Ch∆∞a t√¨m th·∫•y `OPENROUTER_API_KEY`. Vui l√≤ng t·∫°o file `.env` v√† th√™m API Key v√†o."

    try:
        # Configure OpenRouter Client
        client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
            default_headers={
                "HTTP-Referer": "http://localhost:5000",
                "X-Title": "FPTU Career Chatbot",
            }
        )
        
        max_retries = 5
        retry_delay = 2

        for attempt in range(max_retries):
            try:
                completion = await client.chat.completions.create(
                    model="arcee-ai/trinity-large-preview:free", 
                    messages=[
                        {
                            "role": "system",
                            "content": system_prompt
                        },
                        {
                            "role": "user",
                            "content": f"[C√ÇU TR·∫¢ L·ªúI C·ª¶A H·ªåC SINH]\n{user_answers_text}\n\nL∆∞u √Ω: H√£y tr·∫£ l·ªùi ho√†n to√†n b·∫±ng Ti·∫øng Vi·ªát. ƒê·∫£m b·∫£o ph·∫£n h·ªìi ƒë·∫ßy ƒë·ªß c·∫£ 4 ph·∫ßn trong ƒë·ªãnh d·∫°ng ƒë·∫ßu ra."
                        }
                    ],
                    temperature=0.7,
                    top_p=0.9,
                    max_tokens=3000, 
                    extra_body={
                        "repetition_penalty": 1.1
                    }
                )
                return completion.choices[0].message.content
            except Exception as e:
                print(f"Attempt {attempt+1} failed: {e}") # Log l·ªói ra terminal
                if ("429" in str(e) or "400" in str(e)) and attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                    continue
                raise e
            
    except Exception as e:
        return f"‚ö†Ô∏è **ƒê√£ x·∫£y ra l·ªói khi g·ªçi OpenRouter AI:**\n\n{str(e)}"

# --- Routes ---

@app.get("/", response_class=HTMLResponse)
@app.head("/")
async def read_root(request: Request):
    """
    Render landing/registration page.
    """
    return templates.TemplateResponse("register.html", {
        "request": request,
        "version": int(time.time())
    })

@app.post("/quiz", response_class=HTMLResponse)
async def start_quiz(request: Request):
    """
    Handle registration and show quiz.
    """
    form_data = await request.form()
    student_name = form_data.get("student_name", "")
    student_phone = form_data.get("student_phone", "")
    student_email = form_data.get("student_email", "")
    student_province = form_data.get("student_province", "")
    student_school = form_data.get("student_school", "")
    student_cccd = form_data.get("student_cccd", "")

    print(f"DEBUG: Start quiz for {student_name}, School: {student_school}")

    all_questions = await asyncio.to_thread(load_questions)
    # Randomly select 15 questions if available
    if len(all_questions) >= 15:
        selected_questions = random.sample(all_questions, 15)
    else:
        selected_questions = all_questions
    
    # Pass student info to the quiz page - Force string conversion
    student_info = {
        "student_name": str(student_name) if student_name else "",
        "student_phone": str(student_phone) if student_phone else "",
        "student_email": str(student_email) if student_email else "",
        "student_province": str(student_province) if student_province else "",
        "student_school": str(student_school) if student_school else "",
        "student_cccd": str(student_cccd) if student_cccd else ""
    }

    return templates.TemplateResponse("index.html", {
        "request": request,
        "questions": selected_questions,
        "student_info": student_info,
        "version": int(time.time())
    })

@app.post("/submit", response_class=HTMLResponse)
async def submit_quiz(request: Request):
    form_data = await request.form()
    
    student_name = form_data.get("student_name", "")
    print(f"DEBUG: Submit received for '{student_name}'. Form keys: {list(form_data.keys())}")
    
    # Reconstruct the questions/answers mapping
    # Since we don't have the question text in the form keys (only IDs like q_1),
    # we need to look up the text.
    # To do this efficiently, let's load all questions and create a map.
    
    all_questions = await asyncio.to_thread(load_questions)
    question_map = {str(q['id']): q['text'] for q in all_questions}
    
    answers_text = ""
    for key, value in form_data.items():
        if key.startswith("q_"):
            q_id = key.replace("q_", "")
            if q_id in question_map:
                q_text = question_map[q_id]
                answers_text += f"- {q_text}: {value}\n"
    
    if not answers_text:
        return templates.TemplateResponse("result.html", {
            "request": request,
            "advice": "‚ö†Ô∏è B·∫°n ch∆∞a tr·∫£ l·ªùi c√¢u h·ªèi n√†o. Vui l√≤ng quay l·∫°i v√† ho√†n th√†nh b√†i tr·∫Øc nghi·ªám.",
            "version": int(time.time())
        })

    print(f"--- User Answers ---\n{answers_text}\n--------------------")

    # Generate advice
    advice_markdown = await generate_ai_advice(answers_text)
    
    # Save full AI response for debugging
    print(f"\n{'='*80}\nFULL AI RESPONSE:\n{'='*80}\n{advice_markdown}\n{'='*80}\n")
    
    # Extract predicted major
    predicted_major = "Kh√¥ng x√°c ƒë·ªãnh"
    # Regex to find "### 1. üåå K·∫æT QU·∫¢ ƒê·ªäNH V·ªä: [Major Name]"
    match = re.search(r"### 1\. üåå K·∫æT QU·∫¢ ƒê·ªäNH V·ªä:\s*(.+)", advice_markdown)
    if match:
        predicted_major = match.group(1).strip()
        # Clean up any potential markdown formatting like bolding
        predicted_major = predicted_major.replace("*", "").strip()
    
    # Extract sub-majors - search for Section 5 with specific emoji
    sub_major_1 = ""
    sub_major_2 = ""
    
    # Look for Section 5 with exact pattern including emoji üéØ
    section5_patterns = [
        r"###\s*5\.\s*üéØ\s*G·ª¢I √ù 2 NG√ÄNH H·ªåC PH·ª§ ƒê·ªíNG H√ÄNH",  # Exact match
        r"###\s*5\.\s*.*?(?:G·ª¢I √ù|g·ª£i √Ω).*?NG√ÄNH.*?PH·ª§",  # Flexible match
        r"###\s*5[\.:\s]",  # Just section 5 header
    ]
    
    section5_text = ""
    found_pattern = None
    
    for pattern in section5_patterns:
        section5_match = re.search(pattern, advice_markdown, re.IGNORECASE | re.MULTILINE)
        if section5_match:
            found_pattern = pattern
            # Extract text from this point to next ### or ---
            section5_start = section5_match.start()
            # Look for next section header or end marker
            next_section = re.search(r"\n(?:###[^#]|\-\-\-)", advice_markdown[section5_start + 10:])
            if next_section:
                section5_text = advice_markdown[section5_start:section5_start + 10 + next_section.start()]
            else:
                # Take rest of document
                section5_text = advice_markdown[section5_start:]
            
            print(f"\n{'='*60}\nFOUND SECTION 5 with pattern: {pattern[:50]}\n{'='*60}\n{section5_text}\n{'='*60}\n")
            break
    
    # If still no section 5, check if AI even mentioned it
    if not section5_text:
        print("‚ö†Ô∏è WARNING: Section 5 not found in AI response!")
        print("Checking if 'üéØ' or 'ng√†nh ph·ª•' or 'ng√†nh h·ªçc ph·ª•' appears anywhere...")
        if 'üéØ' in advice_markdown:
            print("  ‚úì Found üéØ emoji")
        if re.search(r'ng√†nh.*?ph·ª•', advice_markdown, re.IGNORECASE):
            print("  ‚úì Found 'ng√†nh ph·ª•' text")
        else:
            print("  ‚úó 'ng√†nh ph·ª•' NOT found - AI may not have generated Section 5!")
        
        # Search entire document as fallback
        section5_text = advice_markdown
    
    # Extract sub-major 1 with multiple patterns (support all AI format variations)
    patterns_major_1 = [
        # Format: #### üî∏ **#1 NAME**
        r'####\s*üî∏\s*\*\*#1\s+([^\*\n]+?)\*\*',
        r'####.*?#1\s+\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        # Format: **#Ô∏è‚É£ Ng√†nh ph·ª• 1: NAME**
        r'\*\*#Ô∏è‚É£\s*Ng√†nh ph·ª•\s*1:\s*([^\*\n]+?)\*\*',
        r'#Ô∏è‚É£\s*Ng√†nh ph·ª•\s*1:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        # Template format: **üî∏ Ng√†nh h·ªçc ph·ª• #1: NAME**
        r'\*\*üî∏\s*Ng√†nh h·ªçc ph·ª• #1:\s*([^\*\n]+?)\*\*',
        r'üî∏\s*Ng√†nh h·ªçc ph·ª• #1:\s*\*\*([^\*\n]+?)\*\*',
        # Generic patterns
        r'#1[:\s]+\*?\*?([A-Z·∫Æ·∫∞·∫≤·∫¥·∫∂·∫§·∫¶·∫®·∫™·∫¨ƒê·∫æ·ªÄ·ªÇ·ªÑ·ªÜ√ç√å·ªàƒ®·ªä√ì√í·ªé√ï·ªå√î·ªê·ªí·ªî·ªñ·ªò∆†·ªö·ªú·ªû·ª†·ª¢√ö√ô·ª¶≈®·ª§∆Ø·ª®·ª™·ª¨·ªÆ·ª∞√ù·ª≤·ª∂·ª∏·ª¥\s]+?)(?:\*\*|\n)',
        r'Ng√†nh h·ªçc ph·ª• #1:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        r'ng√†nh.*?ph·ª•.*?#?1:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
    ]
    
    for pattern in patterns_major_1:
        match = re.search(pattern, section5_text, re.IGNORECASE)
        if match:
            sub_major_1 = match.group(1).strip()
            sub_major_1 = re.sub(r'\s*[\(\[].*?[\)\]]', '', sub_major_1)  # Remove (text) or [text]
            sub_major_1 = sub_major_1.strip()
            print(f"‚úì Found sub-major #1: '{sub_major_1}' (pattern: {pattern[:50]}...)")
            break
    
    # Extract sub-major 2
    patterns_major_2 = [
        # Format: #### üî∏ **#2 NAME**
        r'####\s*üî∏\s*\*\*#2\s+([^\*\n]+?)\*\*',
        r'####.*?#2\s+\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        # Format: **#Ô∏è‚É£ Ng√†nh ph·ª• 2: NAME**
        r'\*\*#Ô∏è‚É£\s*Ng√†nh ph·ª•\s*2:\s*([^\*\n]+?)\*\*',
        r'#Ô∏è‚É£\s*Ng√†nh ph·ª•\s*2:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        # Template format: **üî∏ Ng√†nh h·ªçc ph·ª• #2: NAME**
        r'\*\*üî∏\s*Ng√†nh h·ªçc ph·ª• #2:\s*([^\*\n]+?)\*\*',
        r'üî∏\s*Ng√†nh h·ªçc ph·ª• #2:\s*\*\*([^\*\n]+?)\*\*',
        # Generic patterns
        r'#2[:\s]+\*?\*?([A-Z·∫Æ·∫∞·∫≤·∫¥·∫∂·∫§·∫¶·∫®·∫™·∫¨ƒê·∫æ·ªÄ·ªÇ·ªÑ·ªÜ√ç√å·ªàƒ®·ªä√ì√í·ªé√ï·ªå√î·ªê·ªí·ªî·ªñ·ªò∆†·ªö·ªú·ªû·ª†·ª¢√ö√ô·ª¶≈®·ª§∆Ø·ª®·ª™·ª¨·ªÆ·ª∞√ù·ª≤·ª∂·ª∏·ª¥\s]+?)(?:\*\*|\n)',
        r'Ng√†nh h·ªçc ph·ª• #2:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
        r'ng√†nh.*?ph·ª•.*?#?2:\s*\*?\*?([^\*\n]+?)(?:\*\*|\n)',
    ]
    
    for pattern in patterns_major_2:
        match = re.search(pattern, section5_text, re.IGNORECASE)
        if match:
            sub_major_2 = match.group(1).strip()
            sub_major_2 = re.sub(r'\s*[\(\[].*?[\)\]]', '', sub_major_2)
            sub_major_2 = sub_major_2.strip()
            print(f"‚úì Found sub-major #2: '{sub_major_2}' (pattern: {pattern[:40]}...)")
            break
    
    print(f"\nDEBUG: Final extracted values:")
    print(f"  - Main major: '{predicted_major}'")
    print(f"  - Sub-major #1: '{sub_major_1}'")
    print(f"  - Sub-major #2: '{sub_major_2}'\n")

    # Extract student info
    student_data = {
        'student_name': str(form_data.get('student_name', '')),
        'student_phone': str(form_data.get('student_phone', '')),
        'student_email': str(form_data.get('student_email', '')),
        'student_province': str(form_data.get('student_province', '')),
        'student_school': str(form_data.get('student_school', '')),
        'student_cccd': str(form_data.get('student_cccd', '')),
        'predicted_major': predicted_major,
        'sub_major_1': sub_major_1,
        'sub_major_2': sub_major_2,
        'career_advice': advice_markdown
    }
    
    print(f"DEBUG: Processing quiz for {student_data['student_name']} from {student_data['student_school']}")
    
    # Save to Google Sheet (run in background)
    asyncio.create_task(save_student_info(student_data))

    # Convert Markdown to HTML for display
    advice_html = await asyncio.to_thread(markdown.markdown, advice_markdown)
    
    return templates.TemplateResponse("result.html", {
        "request": request,
        "advice": advice_html,
        "version": int(time.time())
    })

@app.get("/favicon.ico")
async def favicon():
    """Handle favicon requests"""
    favicon_path = os.path.join("static", "favicon.ico")
    if os.path.exists(favicon_path):
        return FileResponse(favicon_path)
    # Return empty response if favicon doesn't exist
    return HTMLResponse(content="", status_code=204)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=5000, reload=True)
